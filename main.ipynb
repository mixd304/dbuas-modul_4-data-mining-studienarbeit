{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Einleitung\n",
    "Diese Studienarbeit beschäftigt sich mit der explorativen Datenanalyse sowie der Zeitreihenanalyse von Verkaufsdaten der letzten 2 Jahre von Rossmann in verschiedenen Filialen. Das Ziel dieser Arbeit ist auf Basis der gewonnenen Erkenntnisse eine Vorhersage der Verkaufsentwicklung für die nächsten 6 Wochen zu erstellen. Die Motivation für die Durchführung dieser Analyse liegt darin, die Verkaufsperformance von Rossmann besser zu verstehen und somit mögliche Optimierungspotenziale aufzudecken. Dabei sollen auch Unterschiede in der Verkaufsentwicklung zwischen verschiedenen Filialtypen identifiziert werden, um zielgerichtete Handlungsempfehlungen ableiten zu können.\n",
    "\n",
    "Die Analyse der Verkaufsdaten von Rossmann ermöglicht es, auf Basis von umfassenden Daten einen Einblick in das Kaufverhalten der Kunden und die Leistung der Filialen zu erhalten. Dabei können beispielsweise saisonale Schwankungen, Einflüsse von Promo-Aktionen oder auch Unterschiede in der Verkaufsentwicklung zwischen verschiedenen Filialtypen erkannt werden. Die zeitliche Komponente der Daten erlaubt es, Trends und Muster in der Verkaufsentwicklung zu identifizieren und auf dieser Grundlage zukünftige Verkaufstrends zu prognostizieren.  \n",
    "\n",
    "Die Erkenntnisse aus der vorliegenden Studienarbeit können somit nicht nur für Rossmann, sondern auch für andere Einzelhändler und Unternehmen mit ähnlicher Ausrichtung von großem Nutzen sein. Zudem können die Ergebnisse dieser Analyse als Grundlage für weitere Forschung und Entwicklung im Bereich des Einzelhandels dienen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problemstellung\n",
    "Rossmann ist ein führender Drogeriemarkt in Deutschland und betreibt mehr als 4500 Filialen in Europa, davon mehr als 2200 Filialen in Deutschland.<sup>[1]</sup> Das Geschäftsmodell basiert auf einem breiten Sortiment an Produkten zu niedrigen Preisen und einem hohen Fokus auf Kundenzufriedenheit. Der Verkauf erfolgt in Filialen sowie über den Online-Shop. Zusätzlich bietet Rossmann zahlreiche Eigenmarken und führt regelmäßig Aktionen durch, um Kunden zu binden und neue Kunden zu gewinnen.  \n",
    "\n",
    "Das Verständnis des Geschäftsmodells von Rossmann ist entscheidend für die Durchführung der explorativen Datenanalyse und der Zeitreihenanalyse. Denn nur durch das Verständnis der Geschäftspraktiken und der Verkaufsstrategie kann sichergestellt werden, dass die Analysen auf aussagekräftige Ergebnisse zurückgreifen und so praxisrelevante Handlungsempfehlungen für Rossmann abgeleitet werden können.\n",
    "\n",
    "<sup>[1]</sup> https://unternehmen.rossmann.de/ueber-das-unternehmen.html#:~:text=Mit%2060.500%20Mitarbeitern%20in%20Europa,den%20gr%C3%B6%C3%9Ften%20Drogeriemarktketten%20in%20Europa, abgerufen am 05.05.2023."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Datensatz\n",
    "Der verwendete Datensatz stammt aus der Kaggle Competition \"Rossman Store Sales\".<sup>[2]</sup>  \n",
    "Dieser besteht aus den folgenden 4 Dateien:\n",
    "- sample\n",
    "\n",
    "<sup>[2]</sup> https://www.kaggle.com/competitions/rossmann-store-sales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Package-Installation & Imports\n",
    "Im ersten Schritt sollte eine Python-Umgebung erstellt werden, welche alle benötigten Python-Packages installiert hat. Hierzu sind alle verwendeten Packages in der Datei \"requirements.txt\" aufgelistet. Diese kann verwendet werden um Beispielsweise mit anaconda über den Befehl ```conda create --name dbuas-data-mining-studienarbeit-dariusmix --file requirements.txt```  \n",
    "eine neue Python-Umgebung aufzusetzen. Im Anschluss muss die neu erstellte Umgebung über den Befehl ```conda activate dbuas-data-mining-studienarbeit-dariusmix``` aktiviert werden. Die verwendeten Befehle sind zusätzlich noch einmal in der README.md unter \"Setup\" aufgelistet.  \n",
    "\n",
    "Nachdem alle benötigten Packages installiert wurden, können diese mit dem folgenden Code-Block importiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Einlesen der Daten in ein pandas Dataframe  \n",
    "Nachdem die benötigten Packages importiert wurden, werden die CSV-Dateien \"train.csv\", \"store.csv\" sowie \"test.csv\" eingelesen und in Pandas DataFrames gespeichert. Hierzu werden die Dateipfade der Dateien als Strings in den Variablen \"filepath_train\", \"filepath_test\" und \"filepath_store\" gespeichert und anschließend mithilfe von der Pandas Funktion read_csv() eingelesen und in DataFrames umgewandelt. Die 'index_col'-Parameter werden auf \"Date\" gesetzt, um sicherzustellen, dass das Datum als Index des DataFrames verwendet wird. low_memory=False wird verwendet, um sicherzustellen, dass Pandas genügend Speicherplatz für die Verarbeitung der Daten reserviert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH_TRAIN = os.path.join(\"input\", \"train.csv\")\n",
    "FILEPATH_STORE = os.path.join(\"input\", \"store.csv\")\n",
    "FILEPATH_TEST = os.path.join(\"input\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(FILEPATH_TRAIN, low_memory=False)\n",
    "df_store = pd.read_csv(FILEPATH_STORE)\n",
    "df_test = pd.read_csv(FILEPATH_TEST, low_memory=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Explorative Datenanalyse (EDA)\n",
    "Im ersten Schritt der EDA werden mithilfe des Python-Packages \"ydata_profiling\" die Profiling Reports für die Dateien \"train.csv\" und \"store.csv\" erstellt. Diese befinden sind als html-Dateien im output Ordner unter den Dateinamen \"rossmann-store-sales-train.html\" und \"rossmann-store-sales-store.html\".\n",
    "\n",
    "### Profiling Report\n",
    "\n",
    "Die Datei \"train.csv\" enthält die täglichen Verkaufszahlen (Sales) sowie die Anzahl der Kunden (Customers) von 1115 Filialen aus dem Zeitraum vom 01. Januar 2013 bis zum 31. Juli 2015. Weiterhin beinhaltet die Datei Informationen darüber, ob die Filiale an dem jeweiligen Tag geöffnet war (Open), ob eine Aktion (Promo) stattgefunden hat und ob es sich um einen gesetzlichen Feiertag (StateHoliday) oder Schulferien (SchoolHoliday) handelte.\n",
    "\n",
    "Die Datei \"store.csv\" enthält weitere Informationen zu den Filialen wie den Filialtyp (StoreType), die Sortimentsgröße (Assortment), die Entfernung zum nächsten Wettbewerber (CompetitionDistance) sowie Angaben zu weiteren Promo-Aktionen (Promo2).\n",
    "\n",
    "Train Variablen\n",
    "- Die Daten enthalten keine leeren oder doppelten Zeilen, dementsprechend müssen keine Zellen aufgefüllt werden und keine Redundanzen entfernt werden.\n",
    "- Die Variable \"Date\" gibt den Zeitraum der Daten an, der vom 01.01.2013 bis zum 17.09.2015 reicht.\n",
    "- Die Variable \"Store\" ist eine eindeutige ID für jeden der 1115 unterschiedlichen Stores. Über diese eindeutige ID kann der Datensatz mit der zweiten Datei \"store.csv\" verbunden werden.\n",
    "- Die Variable \"Sales\" gibt den Umsatz für den jeweiligen Tag an, wobei es 172.871 Einträge (ca. 17% aller Einträge) gibt, an denen kein Umsatz generiert wurde (Sales = 0). Der Mittelwert der Sales liegt bei 5744, beinhaltet aber auch die Tage, an denen die Sales 0 sind und die Stores geschlossen sind. Wenn diese Tage herausgefiltert werden, sollte der Mittelwert aussagekräftiger sein. \n",
    "- Die Variable \"Customers\" gibt die Anzahl der Kunden für den jeweiligen Tag an. Es sollte eine weitere Variable berechnet werden, die den Umsatz pro Kunden angibt (Sales / Customers).\n",
    "- Die Variable \"Open\" gibt an, ob das Geschäft an dem jeweiligen Tag geöffnet war. Es gibt 172817 Einträge, bei denen die Stores geschlossen waren (Open = 0). \n",
    "- Die Variable \"Promo\" gibt an, ob ein Geschäft an dem jeweiligen Tag eine Werbeaktion durchgeführt hat. \n",
    "- Die Variable \"StateHoliday\" gibt an, ob es an dem Tag einen gesetzlichen Feiertag gab. Normalerweise sind alle Geschäfte, mit wenigen Ausnahmen, an gesetzlichen Feiertagen geschlossen.\n",
    "- Die Variable \"SchoolHoliday\" gibt an, ob das Geschäft von der Schließung öffentlicher Schulen betroffen war.  \n",
    "\n",
    "Store Variablen\n",
    "- Die Variable \"StoreType\" unterscheidet die Stores zwischen 4 verschiedenen Typen (a, b, c, d).\n",
    "- Die Variable \"Assortment\" gibt an, welches Sortiment der Store im Angebot hat (a = Basis, b = extra, c = erweitert).\n",
    "- Die Variable \"CompetitionDistance\" gibt die Entfernung in Metern bis zum nächstgelegenen Konkurrenzgeschäft an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ea860538034174bf455129c499c0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07db8caa6da04243aae6e4fa9375bb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed38b4769c04d5e8d34b0b6ac637b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4652561c083544a1b8c1479377779599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d553d64e8134ef9bb90eb2c3a21829b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2633df93ea3418a95cd676af4bba107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2c744024954783bbb4ac26ac1b6e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deadf7d530b4bdbaecb45f863f7d40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile_train = ProfileReport(df_train, title=\"Pandas Profiling Report\", explorative=True)\n",
    "profile_train.to_file(os.path.join(\"output\", \"rossmann-store-sales-train.html\"))\n",
    "\n",
    "profile_store = ProfileReport(df_store, title=\"Pandas Profiling Report\", explorative=True)\n",
    "profile_store.to_file(os.path.join(\"output\", \"rossmann-store-sales-store.html\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Unterschied zwischen dem Train-Datensatz und dem Test-Datensatz besteht darin, dass der Test-Datensatz keine Informationen über die Umsätze und Kunden enthält. Das liegt daran, dass der Test-Datensatz die Zukunft abbilden soll und der Train-Datensatz die Vergangenheit. Dementsprechend sollen für die Datumsangaben aus dem Test-Datensatz die Vekaufsdaten vorhergesagt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5  2015-07-31   5263        555     1      1            0   \n",
       "1      2          5  2015-07-31   6064        625     1      1            0   \n",
       "2      3          5  2015-07-31   8314        821     1      1            0   \n",
       "3      4          5  2015-07-31  13995       1498     1      1            0   \n",
       "4      5          5  2015-07-31   4822        559     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Store  DayOfWeek        Date  Open  Promo StateHoliday  SchoolHoliday\n",
       "0   1      1          4  2015-09-17   1.0      1            0              0\n",
       "1   2      3          4  2015-09-17   1.0      1            0              0\n",
       "2   3      7          4  2015-09-17   1.0      1            0              0\n",
       "3   4      8          4  2015-09-17   1.0      1            0              0\n",
       "4   5      9          4  2015-09-17   1.0      1            0              0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinzufügen neuer Variablen  \n",
    "Im nächsten Schritt wird das Datum als Index des DataFrames gesetzt und zusätzliche zeitliche Variablen (Jahr, Monat, Tag und Kalenderwoche) sowie Umsatz pro Kunde hinzugefügt. Diese Variablen werden in den nachfolgenden Codeabschnitten für eine bessere Auswertung und Darstellung benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ersetzen des index durch die Spalte 'Date'\n",
    "df_train.set_index('Date', inplace=True)\n",
    "\n",
    "# Umwandeln des Datums in den Datentyp 'datetime' \n",
    "df_train.index = pd.DatetimeIndex(df_train.index)\n",
    "\n",
    "# Hinzufügen zeitlicher Variablen (Jahr, Monat, Tag und Kalenderwoche und das Datum als Spalte)\n",
    "df_train['Year'] = df_train.index.year\n",
    "df_train['Month'] = df_train.index.month\n",
    "df_train['Day'] = df_train.index.day\n",
    "df_train['WeekOfYear'] = df_train.index.isocalendar().week\n",
    "df_train['Date'] = pd.to_datetime(df_train[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Berechnen einer neuen Variablen 'SalesPerCustomer' - gibt an, wie viel Umsatz je Kunde an dem jeweiligen Tag erwirtschaftet wurde\n",
    "df_train['SalesPerCustomer'] = df_train['Sales']/df_train['Customers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>Date</th>\n",
       "      <th>SalesPerCustomer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-31</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>9.482883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-31</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>9.702400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-31</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>10.126675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-31</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>9.342457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-31</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8.626118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store  DayOfWeek  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "Date                                                                       \n",
       "2015-07-31      1          5   5263        555     1      1            0   \n",
       "2015-07-31      2          5   6064        625     1      1            0   \n",
       "2015-07-31      3          5   8314        821     1      1            0   \n",
       "2015-07-31      4          5  13995       1498     1      1            0   \n",
       "2015-07-31      5          5   4822        559     1      1            0   \n",
       "\n",
       "            SchoolHoliday  Year  Month  Day  WeekOfYear       Date  \\\n",
       "Date                                                                 \n",
       "2015-07-31              1  2015      7   31          31 2015-07-31   \n",
       "2015-07-31              1  2015      7   31          31 2015-07-31   \n",
       "2015-07-31              1  2015      7   31          31 2015-07-31   \n",
       "2015-07-31              1  2015      7   31          31 2015-07-31   \n",
       "2015-07-31              1  2015      7   31          31 2015-07-31   \n",
       "\n",
       "            SalesPerCustomer  \n",
       "Date                          \n",
       "2015-07-31          9.482883  \n",
       "2015-07-31          9.702400  \n",
       "2015-07-31         10.126675  \n",
       "2015-07-31          9.342457  \n",
       "2015-07-31          8.626118  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4. Überprüfen auf NULL-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5. Untersuchung der Variable \"Open\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Open.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeige der Anzahl der Einträge, an welchen die Läden geschlossen (Open = 0) waren und an welchen kein Umsatz (Sales = 0) generiert wurde\n",
    "print('Anzahl Einträge Sales 0:              ', df_train[(df_train.Sales == 0)].shape[0])\n",
    "\n",
    "# Anzeige der Anzahl der Einträge, an denen die Stores geschlossen (Open = 0) waren und kein Umsatz (Sales = 0) generiert wurde\n",
    "print('Anzahl Store geschlossen & Sales = 0: ', df_train[(df_train.Open == 0) & (df_train.Sales == 0)].shape[0])\n",
    "\n",
    "# Anzeige der Anzahl der Einträge, an denen die Stores geöffnet waren (Open = 1) und kein Umsatz (Sales = 0) generiert wurde\n",
    "print('Anzahl Store geöffnet & Sales = 0:    ', df_train[(df_train.Open == 1) & (df_train.Sales == 0)].shape[0])\n",
    "\n",
    "# Prüfen, ob es Einträge gibt, an denen der Store geschlossen war, aber Umsatz erwirtschaft wurde (dies sollte nicht vorkommen und könnte auf Fehlerhafte Daten hinweisen)\n",
    "print('Anzahl Store geschlossen & Sales > 0: ', df_train[(df_train.Open == 0) & (df_train.Sales > 0)].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafik: Verteilung der Wochentage, an welchen die Läden geöffnet bzw. geschlossen waren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.Open.value_counts())\n",
    "\n",
    "sns.countplot(x = 'DayOfWeek', hue = 'Open', data = df_train)\n",
    "plt.title('Verteilung der Wochentage, an welchen die Läden geöffnet bzw. geschlossen waren')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt 172817 Einträge von geschlossenen Stores mit 0 Umsatz (etwa. 17% aller Einträge). Dieser werden aus den Daten entfernt um verzerrte Prognosen zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[(df_train[\"Open\"] != 0) & (df_train['Sales'] != 0)]\n",
    "print(df_train.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.6. Store-Daten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Überblick über die Store-Daten\n",
    "Anzeige der gesamten Anzahl an Zeilen und der ersten 5 Zeilen der Store-Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Anzahl Stores: ', df_store.shape[0])\n",
    "df_store.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Überprüfen auf NULL-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ersetzen von NULL-Werten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CompetitionDistance  \n",
    "distance in meters to the nearest competitor store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store[pd.isnull(df_store.CompetitionDistance)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fehlende Werte der \"CompetitionDistance\" mit dem Median ersetzen\n",
    "df_store['CompetitionDistance'].fillna(df_store['CompetitionDistance'].median(), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CompetitionOpenSince[Month/Year]  \n",
    "gives the approximate year and month of the time the nearest competitor was opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfen, ob es CompetitionOpenSince[Month/Year] zusammenhänge gibt, bei denen CompetitionOpenSince[Month/Year] NULL ist\n",
    "df_CompetitionOpenSinceMonth = df_store[pd.isnull(df_store.CompetitionOpenSinceMonth)]\n",
    "df_CompetitionOpenSinceMonth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Month', df_store['CompetitionOpenSinceMonth'].median())\n",
    "print('Year', df_store['CompetitionOpenSinceYear'].median())\n",
    "df_store['CompetitionOpenSinceYear'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es scheint keine Zusammenhänge mit den anderen Werten zu geben, da NULLs aber entfernt werden müssen, werden die Daten mit 0 ersetzt\n",
    "df_store['CompetitionOpenSinceMonth'].fillna(0, inplace=True)\n",
    "df_store['CompetitionOpenSinceYear'].fillna(0, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Promo2 Zusatzfelder \n",
    "\n",
    "Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating  \n",
    "Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2  \n",
    "PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfen, ob es zusammenhänge gibt, bei denen die Promo2 Zusatzfelder NULL sind\n",
    "df_Promo2SinceWeek = df_store[pd.isnull(df_store.Promo2SinceWeek)]\n",
    "df_Promo2SinceWeek.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es sieht so aus, als wären die Felder NULL wenn Promo2 = 0 ist\n",
    "\n",
    "# Prüfen, ob Promo2SinceWeek, Promo2SinceYear, PromoInterval nur NULL sind, wenn Promo2 auch 0 ist (also der Store an keiner Promo teilnimmt)\n",
    "df_Promo2SinceWeek = df_store[pd.isnull(df_store.Promo2SinceWeek)]\n",
    "print(df_Promo2SinceWeek[df_Promo2SinceWeek.Promo2 != 0].shape[0])\n",
    "\n",
    "df_Promo2SinceYear = df_store[pd.isnull(df_store.Promo2SinceYear)]\n",
    "print(df_Promo2SinceYear[df_Promo2SinceYear.Promo2 != 0].shape[0])\n",
    "\n",
    "df_PromoInterval = df_store[pd.isnull(df_store.PromoInterval)]\n",
    "print(df_PromoInterval[df_PromoInterval.Promo2 != 0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ja, NULL in den 3 Spalten bedeutet, dass es keine Information über eine Promo gibt\n",
    "# Ersetzen der NULL Werte durch 0\n",
    "df_store['Promo2SinceWeek'].fillna(0, inplace=True)\n",
    "df_store['Promo2SinceYear'].fillna(0, inplace=True)\n",
    "df_store['PromoInterval'].fillna(0, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erneutes Überprüfen auf NULL-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.7. Zusammenführen der Daten mit den Store-Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_store = pd.merge(df_train, df_store, on=\"Store\", how=\"inner\")\n",
    "df_test_store = pd.merge(df_test, df_store, on=\"Store\", how=\"inner\")\n",
    "df_train_store.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.8. Korrelation\n",
    "Im nächsten Schritt wird analysiert, zwischen welchen Daten es eine Korrelation gibt\n",
    "\n",
    "Es ist zu erkennen, dass eine starke Korrelation zwischen der Anzahl der Kunden und dem Umsatz besteht. Zusätzlich gibt es eine Korrelation zwischen Promo und Customers.\n",
    "Die anderen Korrelationen (WeekOfYear + Month oder Promo2 + Promo2SinceYear) werden nicht näher betrachtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neue Variable erstellen, welche die Korrelation enthält (Open wird entfernt, weil Open nur eine 1 enthält)\n",
    "corr = df_train_store.copy()\n",
    "corr['Assortment'] = corr['Assortment'].replace(['a', 'b', 'c'], [1, 2, 3])\n",
    "corr['StoreType'] = corr['StoreType'].replace(['a', 'b', 'c', 'd'], [1, 2, 3, 4])\n",
    "corr = corr.drop('Open', axis=1).corr()\n",
    "\n",
    "# Maske für die obere Dreiecksmatrix erstellen (damit nur die untere Hälfte angezeigt wird)\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "sns.heatmap(corr, cmap='coolwarm', mask=mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.9. StoreTypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StoreTypes - Gesamt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe nach Storetype sortieren\n",
    "damit in den folgenden Grafiken der Storetype a ganz links und der Storetype d ganz rechts ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_store = df_train_store.sort_values(by='StoreType')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: Sales je Storetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_store.groupby('StoreType')[['StoreType', 'Sales']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn man die Daten nach Storetypes aufsplittet und die Sales analysiert, ist zu sehen, dass der Storetype B den höchsten Umsatz-Durchschnitt pro Store pro Tag besitzt, allerdings auch die wenigstens Einträge.\n",
    "\n",
    "sns.boxplot(data=df_train_store, x='StoreType', y='Sales')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: Sales, Kunden & Sales pro Kunde je Storetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_store.groupby('StoreType')[['Customers', 'Sales']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn wir uns nun die Anzahl der Kunden und die gesamten Umsatzzahlen pro Storetype angucken, sieht man, dass Storetype A die meisten Kunden und insgesamt auch den größten Umsatz erwirtschaftet.\n",
    "\n",
    "df_sales = df_train_store.groupby('StoreType')['Sales'].sum().reset_index()\n",
    "df_customers = df_train_store.groupby('StoreType')['Customers'].sum().reset_index()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "\n",
    "sns.barplot(data=df_sales, x='StoreType', y='Sales', color='b', ax=ax1)\n",
    "sns.barplot(data=df_customers, x='StoreType', y='Customers', color='g', ax=ax2)\n",
    "\n",
    "ax1.set_title('Sales')\n",
    "ax1.set_xlabel('Store Type')\n",
    "\n",
    "ax2.set_title('Customers')\n",
    "ax2.set_xlabel('Store Type')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: Sales pro Kunde je Storetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_store.groupby('StoreType')[['StoreType', 'SalesPerCustomer']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn wir uns nun den Umsatz je Kunden angucken, sieht man, dass Storetype D den höchsten und Storetype B den niedrigsten Umsatz pro Kunden erwirtschaftet.\n",
    "\n",
    "sns.boxplot(data=df_train_store, x='StoreType', y='SalesPerCustomer')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StoreTypes - zeitliche Trends"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: Sales Timeline nach Jahr, Monat und StoreType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_store.groupby(['Year', 'Month', 'StoreType'])['Sales'].sum().unstack().plot(kind='line')\n",
    "plt.title('Sales nach Monat und StoreType')\n",
    "plt.xlabel('Monat')\n",
    "plt.ylabel('Sales')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: Sales Timeline nach Jahr, Woche und StoreType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_store.groupby(['Year', 'WeekOfYear', 'StoreType'])['Sales'].sum().unstack().plot(kind='line')\n",
    "plt.title('Sales nach Woche und StoreType')\n",
    "plt.xlabel('Woche')\n",
    "plt.ylabel('Sales')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: Sales, Customer & SalesPerCustomer monatlicher Trend je StoreType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_train_store, x='Month', y='Sales',\n",
    "            col='StoreType',\n",
    "            palette='bright',\n",
    "            hue='StoreType',\n",
    "            kind='point'\n",
    "           )\n",
    "\n",
    "sns.catplot(data=df_train_store, x='Month', y='Customers',\n",
    "            col='StoreType',\n",
    "            palette='bright',\n",
    "            hue='StoreType',\n",
    "            kind='point'\n",
    "           )\n",
    "\n",
    "sns.catplot(data=df_train_store, x='Month', y='SalesPerCustomer',\n",
    "            col='StoreType',\n",
    "            palette='bright',\n",
    "            hue='StoreType',\n",
    "            kind='point'\n",
    "           )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: Sales monatlicher Trend aufgesplittet nach Jahren und StoreType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_train_store, x='Month', y='Sales',\n",
    "            col='StoreType',\n",
    "            palette='bright',\n",
    "            hue='Year',\n",
    "            kind='point'\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: Sales wöchentlicher Trend und StoreType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wird für die Anzeige der X-Achse verwendet (um nicht jeden Monat anzuzeigen)\n",
    "x_ticks = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49]\n",
    "\n",
    "g = sns.catplot(data=df_train_store, x='WeekOfYear', y='Sales',\n",
    "                col='StoreType',\n",
    "                palette='bright',\n",
    "                hue='StoreType',\n",
    "                kind='point'\n",
    "                )\n",
    "\n",
    "# Legt die Achseneinteilung fest\n",
    "for ax in g.axes.flatten():\n",
    "    ax.set_xticks(x_ticks)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StoreTypes - nach Wochentag"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: Sales nach DayOfWeek und Storetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_train_store, x='DayOfWeek', y='Sales',\n",
    "            col='StoreType',\n",
    "            palette='bright',\n",
    "            hue='StoreType',\n",
    "            kind='point'\n",
    "           )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: Sales nach Monat, DayOfWeek und Storetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_train_store, x='Month', y='Sales',\n",
    "            col='DayOfWeek',\n",
    "            palette='bright',\n",
    "            hue='StoreType',\n",
    "            row=\"StoreType\",\n",
    "            kind='point'\n",
    "           )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.10. Assortment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_store.groupby('Assortment')[['Assortment', 'Sales']].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: Sales nach DayOfWeek und Assortment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_train_store, x='DayOfWeek', y='Sales',\n",
    "            col='Assortment',\n",
    "            palette='bright',\n",
    "            hue='Assortment',\n",
    "            kind='point'\n",
    "           )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: Sales, Customer & SalesPerCustomer monatlicher Trend je Assortment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_train_store, x='Month', y='Sales',\n",
    "            col='Assortment',\n",
    "            palette='bright',\n",
    "            hue='Assortment',\n",
    "            kind='point'\n",
    "           )\n",
    "\n",
    "sns.catplot(data=df_train_store, x='Month', y='Customers',\n",
    "            col='Assortment',\n",
    "            palette='bright',\n",
    "            hue='Assortment',\n",
    "            kind='point'\n",
    "           )\n",
    "\n",
    "sns.catplot(data=df_train_store, x='Month', y='SalesPerCustomer',\n",
    "            col='Assortment',\n",
    "            palette='bright',\n",
    "            hue='Assortment',\n",
    "            kind='point'\n",
    "           )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.11. Promo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung: SalesPerCustomer nach Monat, Storetype und Promo / Promo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_train_store, x='Month', y='SalesPerCustomer',\n",
    "            col='StoreType',\n",
    "            palette='bright',\n",
    "            hue='Promo',\n",
    "            kind='point'\n",
    "           )\n",
    "\n",
    "sns.catplot(data=df_train_store, x='Month', y='SalesPerCustomer',\n",
    "            col='StoreType',\n",
    "            palette='bright',\n",
    "            hue='Promo2',\n",
    "            kind='point'\n",
    "           )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafik: SalesPerCustomer nach DayOfWeek, Storetype und Promo / Promo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_train_store, x='DayOfWeek', y='SalesPerCustomer',\n",
    "            col='StoreType',\n",
    "            palette='bright',\n",
    "            hue='Promo',\n",
    "            kind='point'\n",
    "           )\n",
    "\n",
    "sns.catplot(data=df_train_store, x='DayOfWeek', y='SalesPerCustomer',\n",
    "            col='StoreType',\n",
    "            palette='bright',\n",
    "            hue='Promo2',\n",
    "            kind='point'\n",
    "           )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. EDA Zusammenfassung\n",
    "  - Es besteht eine starke Korrelation zwischen der Anzahl an Kunden und dem Umsatz\n",
    "  - Storetype B generiert den höchsten Umsatz pro Tag\n",
    "  - Storetype B generiert den niedrigsten Umsatz pro Kunden\n",
    "  - Storetype D generiert den höchsten Umsatz pro Kunden\n",
    "  - Storetype A generiert den größten Gesamtumsatz, hat aber auch die meisten Kunden\n",
    "  - Storetype C ist an Sonntagen geschlossen\n",
    "  - Storetype D ist nur im November an Sonntagen geschlossen\n",
    "  -\n",
    "  - Im Dezember gibt es (unabhängig vom Storetype) ein starkes Umsatzwachstum\n",
    "  - \n",
    "  - \n",
    "  - \n",
    "\n",
    "Promo2 alone doesn't seem to be correlated to any significant change in the Sales amount.\n",
    "Customers tends to buy more on Modays when there's one promotion (Promo) and on Sundays when there's no promotion at all (both Promo and Promo1 are equal to 0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Zeitreihenanalyse und Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose as sm\n",
    "from prophet import Prophet\n",
    "import xgboost as xgb\n",
    "\n",
    "filepath_train = \"../input/train.csv\"\n",
    "filepath_test = \"../input/test.csv\"\n",
    "filepath_store = \"../input/store.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der Daten\n",
    "df_train = pd.read_csv(filepath_train, low_memory=False, index_col = 'Date')\n",
    "df_test = pd.read_csv(filepath_test, low_memory=False, index_col = 'Date')\n",
    "df_store = pd.read_csv(filepath_store)\n",
    "\n",
    "# Umwandeln des Datums im Index in den Datentyp 'datetime'\n",
    "df_train.index = pd.to_datetime(df_train.index)\n",
    "df_test.index = pd.to_datetime(df_test.index)\n",
    "\n",
    "# Hinzufügen neuer Variablen\n",
    "df_train['Year'] = df_train.index.year\n",
    "df_train['Month'] = df_train.index.month\n",
    "df_train['Day'] = df_train.index.day\n",
    "df_train['WeekOfYear'] = df_train.index.weekofyear\n",
    "df_train['Date'] = pd.to_datetime(df_train[['Year', 'Month', 'Day']])\n",
    "df_train['SalesPerCustomer'] = df_train['Sales']/df_train['Customers']\n",
    "\n",
    "df_test['Year'] = df_test.index.year\n",
    "df_test['Month'] = df_test.index.month\n",
    "df_test['Day'] = df_test.index.day\n",
    "df_test['WeekOfYear'] = df_test.index.weekofyear\n",
    "df_test['Date'] = pd.to_datetime(df_test[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Entfernen der Einträge, an denen die Stores geschlossen waren und kein Umsatz generiert haben\n",
    "df_train = df_train[(df_train[\"Open\"] != 0) & (df_train['Sales'] != 0)]\n",
    "\n",
    "# NULLs entfernen\n",
    "df_store['CompetitionDistance'].fillna(df_store['CompetitionDistance'].median(), inplace=True)\n",
    "df_store['CompetitionOpenSinceMonth'].fillna(0, inplace=True)\n",
    "df_store['CompetitionOpenSinceYear'].fillna(0, inplace=True)\n",
    "df_store['Promo2SinceWeek'].fillna(0, inplace=True)\n",
    "df_store['Promo2SinceYear'].fillna(0, inplace=True)\n",
    "df_store['PromoInterval'].fillna(0, inplace=True)\n",
    "df_test['Open'].fillna(1, inplace = True)\n",
    "\n",
    "df_train_store = pd.merge(df_train, df_store, on=\"Store\", how=\"inner\")\n",
    "df_test_store = pd.merge(df_test, df_store, on=\"Store\", how=\"inner\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzeige eines Stores je Storetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pro Storetype einen Store anzeigen (wird im folgenden Code in einem Array gespeichert)\n",
    "store_types = df_train_store.StoreType.unique()\n",
    "store_per_storetype = []\n",
    "\n",
    "for store_type in store_types:\n",
    "    store = df_train_store[df_train_store.StoreType == store_type].Store.unique()\n",
    "    store_per_storetype.append([store_type, store[0]])\n",
    "\n",
    "# Ausgabe von jeweils einem Store je Storetype\n",
    "for store_type, store in store_per_storetype:\n",
    "    print(store_type, ' - ', store)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Zeitreihenanalyse mit seasonal_decompose  \n",
    "\n",
    "Der nachfolgende Code führt eine saisonale Zeitreihenanalyse durch, um die verschiedenen Komponenten (Trend, saisonale und Rest) der Verkaufsdaten nach StoreType zu untersuchen. Hierfür wird die Bibliothek \"statsmodels.tsa.seasonal\" mit der Funktion \"seasonal_decompose\" verwendet. Die \"seasonal_decompose\"-Funktion zerlegt eine Zeitreihe in ihre Komponenten, um Trends und saisonale Muster zu identifizieren.\n",
    "\n",
    "Der Code liest das DataFrame mit den Verkaufsdaten ein und sogruppiert rtiert dieses anschließend nach \"StoreType\" und \"Date\", um die Verkaufsdaten pro Tag und StoreType zu aggregieren. Ein neuer DataFrame wird erstellt, der die aggregierten Verkaufsdaten enthält, mit \"Date\" als Index und \"Sales\" als Wert, die jeweils einem bestimmten \"StoreType\" zugeordnet sind.\n",
    "\n",
    "Als nächstes wird der DataFrame auf eine tägliche Frequenz umgestellt und dann wird eine Schleife durch alle Spalten im DataFrame durchgeführt. Für jeden StoreType wird die \"seasonal_decompose\"-Funktion aufgerufen, um die Zeitreihe der Verkaufsdaten in die Trend-, saisonale- und Restkomponenten zu zerlegen. Das Ergebnis wird grafisch dargestellt und mit \"plt.show()\" angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by StoreType and Date\n",
    "df_grouped = df_train_store.groupby(['StoreType', 'Date']).sum().reset_index()\n",
    "\n",
    "# Create a new DataFrame with Date as index and Sales as values\n",
    "df_sales = df_grouped.pivot(index='Date', columns='StoreType', values='Sales')\n",
    "\n",
    "# Resample to daily frequency\n",
    "df_sales = df_sales.resample('D').sum()\n",
    "\n",
    "# Decompose time series into trend, seasonal, and residual components\n",
    "for store_type in df_sales.columns:\n",
    "    result = sm(df_sales[store_type], model='additive', period=365)\n",
    "    result.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Zeitreihenanalyse und Forecast mit Prophet\n",
    "Quick-Start Guide für Prophet: https://facebook.github.io/prophet/docs/quick_start.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Prophet Forecast-Beispiel anhand von einem Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = df_train_store[df_train_store.Store == 1].loc[:, ['Date', 'Sales']]\n",
    "f = plt.figure(figsize=(18,10))\n",
    "ax1 = f.add_subplot(211)\n",
    "ax1.plot(store['Date'], store['Sales'], '-')\n",
    "ax1.set_xlabel('Zeit')\n",
    "ax1.set_ylabel('Umsatz')\n",
    "ax1.set_title('Umsatz Zeitreihe für Store 1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen des Dataframes, welches zum Forecasting verwendet wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setzen des Datums als Index für die Zeitreihenanalyse\n",
    "df_train_store.set_index('Date', inplace=True)\n",
    "df_train_store['Date'] = pd.to_datetime(df_train_store[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Im folgenden wird der Forecast für \n",
    "sales = df_train_store[df_train_store.Store == 1].loc[:, ['Date', 'Sales']]\n",
    "\n",
    "# reverse to the order: from 2013 to 2015\n",
    "sales = sales.sort_index(ascending = False)\n",
    "\n",
    "# to datetime64\n",
    "sales['Date'] = pd.DatetimeIndex(sales['Date'])\n",
    "\n",
    "# from the prophet documentation every variables should have specific names\n",
    "sales = sales.rename(columns = {'Date': 'ds',\n",
    "                                'Sales': 'y'})\n",
    "sales.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen des Dataframes, welches die Feiertage abbildet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create holidays dataframe\n",
    "state_dates = df_train_store[(df_train_store.StateHoliday == 'a') | (df_train_store.StateHoliday == 'b') & (df_train_store.StateHoliday == 'c')].loc[:, 'Date'].values\n",
    "school_dates = df_train_store[df_train_store.SchoolHoliday == 1].loc[:, 'Date'].values\n",
    "\n",
    "state = pd.DataFrame({'holiday': 'state_holiday',\n",
    "                      'ds': pd.to_datetime(state_dates)})\n",
    "school = pd.DataFrame({'holiday': 'school_holiday',\n",
    "                      'ds': pd.to_datetime(school_dates)})\n",
    "\n",
    "holidays = pd.concat((state, school))      \n",
    "holidays.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Festlegen der Rahmenbedingungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the uncertainty interval to 95% (the Prophet default is 80%)\n",
    "m = Prophet(interval_width = 0.95, holidays = holidays)\n",
    "m.fit(sales)\n",
    "\n",
    "# Erstellen eines DataFrame mit zukünftigen Daten für die nächsten 6 Monate (183 Tage)\n",
    "future = m.make_future_dataframe(periods = 183)\n",
    "\n",
    "# Anzeige der letzten 7 Tage\n",
    "future.tail(7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausführen des Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = m.predict(future)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisierung der Forecastergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = m.plot(forecast)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisierung der Komponenten des Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = m.plot_components(forecast)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Forecast für 5 Shops je Storetype mit Prophet  \n",
    "Quick-Start Guide für Prophet: https://facebook.github.io/prophet/docs/quick_start.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setzen des Datums als Index für die Zeitreihenanalyse \n",
    "df_train_store.set_index('Date', inplace=True)\n",
    "df_train_store['Date'] = pd.to_datetime(df_train_store[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Erstellen des Dataframes für die Feiertage\n",
    "state_dates = df_train_store[(df_train_store.StateHoliday == 'a') | (df_train_store.StateHoliday == 'b') & (df_train_store.StateHoliday == 'c')].loc[:, 'Date'].values\n",
    "school_dates = df_train_store[df_train_store.SchoolHoliday == 1].loc[:, 'Date'].values\n",
    "\n",
    "state = pd.DataFrame({'holiday': 'state_holiday',\n",
    "                      'ds': pd.to_datetime(state_dates)})\n",
    "school = pd.DataFrame({'holiday': 'school_holiday',\n",
    "                      'ds': pd.to_datetime(school_dates)})\n",
    "\n",
    "holidays = pd.concat((state, school))\n",
    "\n",
    "# Aufteilen der Daten nach Storetyp\n",
    "store_types = df_train_store.StoreType.unique()\n",
    "\n",
    "# Initialisiere ein leeres DataFrame, um den Forecast für alle Stores zu speichern\n",
    "prophet_all_forecasts = pd.DataFrame()\n",
    "\n",
    "# Da es insgesamt 1115 Stores gibt und der Forecast für alle Stores sehr lange dauern würde, wird der Forecast für 5 Stores je Storetype durchgeführt\n",
    "for store_type in store_types:\n",
    "    stores = df_train_store[df_train_store.StoreType == store_type].Store.unique()[:1]\n",
    "\n",
    "    for store in stores:\n",
    "        # Sales für den aktuellen Store\n",
    "        sales = df_train_store[df_train_store.Store == store].loc[:, ['Date', 'Sales']]\n",
    "\n",
    "        # Datum von 2013 bis 2015 sortieren\n",
    "        sales = sales.sort_index(ascending = False)\n",
    "\n",
    "        # Konvertieren des Datums in datetime64\n",
    "        sales['Date'] = pd.DatetimeIndex(sales['Date'])\n",
    "\n",
    "        # Umbenennen der Spalten, da prophet das Datum als 'ds' und die abhängige Variable als 'y' erwartet\n",
    "        sales = sales.rename(columns = {'Date': 'ds', \n",
    "                                        'Sales': 'y'})\n",
    "        \n",
    "        # Initialisieren eines Prophet-Modells mit 95% Unsicherheitsintervall und den Feiertagen\n",
    "        m = Prophet(interval_width = 0.95, holidays = holidays)\n",
    "\n",
    "        # Anpassen des Modells an die Sales\n",
    "        m.fit(sales)\n",
    "\n",
    "        # Erstellen eines DataFrame mit zukünftigen Daten für die nächsten 6 Monate (183 Tage)\n",
    "        future = m.make_future_dataframe(periods = 183)\n",
    "\n",
    "        # Generieren des Forecasts für die zukünftigen Daten\n",
    "        forecast = m.predict(future)\n",
    "\n",
    "        # Store-Informationen zum Forecast-Dataframe hinzufügen\n",
    "        forecast['store'] = store\n",
    "        forecast['store_type'] = store_type\n",
    "\n",
    "        # Anhängen des Forecasts für den aktuellen Store an das all_forecasts-DataFrame\n",
    "        prophet_all_forecasts = pd.concat([prophet_all_forecasts, forecast])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export des Forecasts in eine SQLite Datenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_all_forecasts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbindung zur Datenbank herstellen - wenn die Datenbank nicht existiert, wird sie automatisch erstellt\n",
    "conn = sqlite3.connect('../output/rossmann-store-sales.db')\n",
    "\n",
    "# Cursor erstellen\n",
    "c = conn.cursor()\n",
    "\n",
    "# Tabelle erstellen, falls sie nicht bereits existiert\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS sales_forecast_prophet\n",
    "             (id INTEGER PRIMARY KEY,\n",
    "              store INTEGER,\n",
    "              store_type TEXT,\n",
    "              date TEXT,\n",
    "              yhat REAL,\n",
    "              yhat_lower REAL,\n",
    "              yhat_upper REAL\n",
    "              )''')\n",
    "\n",
    "# Tabelle leeren, falls sie bereits existiert und Daten enthält\n",
    "c.execute('''delete from sales_forecast_prophet''')\n",
    "\n",
    "prophet_all_forecasts = prophet_all_forecasts[['store', 'store_type', 'ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "\n",
    "for row in prophet_all_forecasts.iterrows():\n",
    "    store = row[1]['store']\n",
    "    store_type = row[1]['store_type']\n",
    "    ds = row[1]['ds'].strftime('%Y-%m-%d')\n",
    "    yhat = row[1]['yhat']\n",
    "    yhat_lower = row[1]['yhat_lower']\n",
    "    yhat_upper = row[1]['yhat_upper']\n",
    "\n",
    "    c.execute('''INSERT INTO sales_forecast_prophet (store, store_type, date, yhat, yhat_lower, yhat_upper)\n",
    "                    VALUES (?, ?, ?, ?, ?, ?)''', (store, store_type, ds, yhat, yhat_lower, yhat_upper))\n",
    "\n",
    "# Änderungen bestätigen\n",
    "conn.commit()\n",
    "\n",
    "# Verbindung schließen\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Zeitreihenanalyse und Forecast mit XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. XGBoost Forecast-Beispiel anhand von einem Store"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Forecast für 5 Shops je Storetype mit XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set date as index for time series analysis\n",
    "df_train_store.set_index('Date', inplace=True)\n",
    "\n",
    "# Convert date to datetime format\n",
    "df_train_store.index = pd.to_datetime(df_train_store.index)\n",
    "\n",
    "# Split data by store type\n",
    "store_types = df_train_store.StoreType.unique()\n",
    "\n",
    "# Initialize an empty dataframe to store the forecast for all stores\n",
    "xgboost_all_forecasts = pd.DataFrame()\n",
    "\n",
    "# As there are a total of 1115 stores, we will forecast for 5 stores per store type\n",
    "for store_type in store_types:\n",
    "    stores = df_train_store[df_train_store.StoreType == store_type].Store.unique()[:1]\n",
    "\n",
    "    for store in stores:\n",
    "        # Get sales for current store\n",
    "        sales = df_train_store[df_train_store.Store == store].loc[:, ['Sales']]\n",
    "\n",
    "        # Create features for forecasting\n",
    "        sales['day_of_week'] = sales.index.dayofweek\n",
    "        sales['week'] = sales.index.week\n",
    "        sales['month'] = sales.index.month\n",
    "        sales['year'] = sales.index.year\n",
    "\n",
    "        # Split data into training and testing sets\n",
    "        train = sales[sales.index < '2015-06-01']\n",
    "        test = sales[sales.index >= '2015-06-01']\n",
    "\n",
    "        # Create DMatrix for training and testing sets\n",
    "        dtrain = xgb.DMatrix(train.drop(['Sales'], axis=1), label=train['Sales'])\n",
    "        dtest = xgb.DMatrix(test.drop(['Sales'], axis=1))\n",
    "\n",
    "        # Define XGBoost parameters\n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eta': 0.1,\n",
    "            'max_depth': 6,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'seed': 42\n",
    "        }\n",
    "\n",
    "        # Train XGBoost model\n",
    "        model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "        # Generate forecast for future days\n",
    "        future_dates = pd.date_range(start='2015-06-02', end='2015-07-31', freq='D')\n",
    "        future_sales = pd.DataFrame(index=future_dates)\n",
    "        future_sales['day_of_week'] = future_sales.index.dayofweek\n",
    "        future_sales['week'] = future_sales.index.week\n",
    "        future_sales['month'] = future_sales.index.month\n",
    "        future_sales['year'] = future_sales.index.year\n",
    "        future_dmatrix = xgb.DMatrix(future_sales)\n",
    "        future_sales['Sales'] = model.predict(future_dmatrix)\n",
    "\n",
    "        # Add store information to forecast dataframe\n",
    "        future_sales['Store'] = store\n",
    "        future_sales['StoreType'] = store_type\n",
    "\n",
    "        # Append forecast for current store to all_forecasts dataframe\n",
    "        xgboost_all_forecasts = pd.concat([xgboost_all_forecasts, future_sales])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export des Forecasts in eine SQLite Datenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_all_forecasts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbindung zur Datenbank herstellen - wenn die Datenbank nicht existiert, wird sie automatisch erstellt\n",
    "conn = sqlite3.connect('../output/rossmann-store-sales.db')\n",
    "\n",
    "# Cursor erstellen\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('''drop table sales_forecast_xgboost''')\n",
    "\n",
    "# Tabelle erstellen, falls sie nicht bereits existiert\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS sales_forecast_xgboost\n",
    "             (id INTEGER PRIMARY KEY,\n",
    "              store INTEGER,\n",
    "              store_type TEXT,\n",
    "              date TEXT,\n",
    "              y REAL,\n",
    "              y_pred REAL\n",
    "              )''')\n",
    "\n",
    "# Tabelle leeren, falls sie bereits existiert und Daten enthält\n",
    "c.execute('''delete from sales_forecast_xgboost''')\n",
    "\n",
    "xgboost_all_forecasts = xgboost_all_forecasts[['store', 'store_type', 'ds', 'y', 'y_pred']]\n",
    "\n",
    "for row in xgboost_all_forecasts.iterrows():\n",
    "    store = row[1]['store']\n",
    "    store_type = row[1]['store_type']\n",
    "    ds = row[1]['ds'].strftime('%Y-%m-%d')\n",
    "    y = row[1]['y']\n",
    "    y_pred = row[1]['y_pred']\n",
    "\n",
    "    c.execute('''INSERT INTO sales_forecast_xgboost (store, store_type, date, y, y_pred)\n",
    "                    VALUES (?, ?, ?, ?, ?)''', (store, store_type, ds, y, y_pred))\n",
    "\n",
    "# Änderungen bestätigen\n",
    "conn.commit()\n",
    "\n",
    "# Verbindung schließen\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Vergleich der Forecasts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Fazit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "0cd368f941d0f8bc02f7e053f703964ba5c19734093de8c1548a8678bf998c69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
